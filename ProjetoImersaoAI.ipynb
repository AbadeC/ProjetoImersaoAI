{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPODAzC7MdkcUbMZxlY319H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbadeC/ProjetoImersaoAI/blob/main/ProjetoImersaoAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introdução\n",
        "\n"
      ],
      "metadata": {
        "id": "aduEI6btvrTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A proposta deste projeto é criar um Chatbot que responda as perguntas dos usuários com base em PDFs preparados como Base de Conhecimento. Seus usos serão em interação com Clientes, Fornecedores, comunidade ou mesmo para ajudar estudantes em seus estudos.\n",
        "\n",
        "### Funcionamento\n",
        "O funcionamento do programa é simples:\n",
        "- Preparando o Ambiente: realizadas as instalações e importações, configurados os parâmetros;\n",
        "- Preparando a Base de Conhecimento: São realizados os uploads de arquivo para a área de trabalho do colab (/content/). Podem ser enviados um ou mais arquivos em PDF, preparados especificamente para servir como base de conhecimento ou não (a eficiência da ferramenta depende disso);\n",
        "- Executando o trabalho: é aqui que acontece a interação entre o usuário e o chat. Para terminar, teclar ENTER duas vezes consecutivas;\n",
        "- Auxiliares e uso futuro: rotinas para lidar com os arquivos carregados (mostrar e apagar) e para serem usadas futuramente.\n",
        "\n",
        "### Melhorias futuras\n",
        "As possibilidades de melhoria são muitas, commo por exemplo:\n",
        "* Ampliação da Base de Conhecimento opcionais:\n",
        " - Links externos\n",
        " - Outros tipos de arquivo\n",
        " - Imagens\n",
        "* Interface amigável\n",
        "* Inclusão de ícone de avatar para o Chatbot\n",
        "* Parametrizações de acordo com o interesse do Usuário:\n",
        " - Personalidade\n",
        " - Estilo\n",
        " - Escolha de um nome para o Chatbot\n"
      ],
      "metadata": {
        "id": "yrIRNijeyd_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Preparando o Ambiente"
      ],
      "metadata": {
        "id": "yxSGhsxlRdbl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "-gwtT1SHPCgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf0be80-1964-42a8-83bf-237169cab6b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "#Instalando bibliotecas externas\n",
        "!pip install -q -U google-generativeai #SDK do Gemini\n",
        "!pip install PyPDF2     #Para os PDFs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importações de bibliotecas já embutidas no Colab e configurações iniciais\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "\n",
        "from IPython.display import Image   # Para a imagem do Zig\n",
        "\n",
        "# Importação do SDK do Python\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('SECRET_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "XT_TVI8iPnCh"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializando o Modelo (1)\n",
        "# Definições básicas para o Modelo\n",
        "\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 0,\n",
        "  \"max_output_tokens\": 8192,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "]"
      ],
      "metadata": {
        "id": "kkGSA1dbrcIP"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variáveis úteis\n",
        "\n",
        "# Instruções de sistema: Definindo as características e a personalidade do Chatbot.\n",
        "system_instruction = \"Você é um assistente de bate-papo prestativo chamado ZIG. Seja gentil, educado e entusiasta. Responda sempre as perguntas em português brasileiro. Aja como um especialista nos assuntos das Bases de Conhecimento a que tem acesso e utilize o contexto fornecido para responder às perguntas do usuário da forma mais completa e precisa possível. Apresente as informações de forma clara, concisa e organizada. Se a resposta puder ser encontrada em diferentes partes do contexto, combine as informações relevantes. Se a pergunta se referir a requisitos ou documentos, assegure-se de incluir tudo, sem omitir nada. Se a resposta não estiver no contexto, diga que não a sabe, peça desculpas e sugira que o usuário entre em contato com o suporte para obter informações. Lembre-se: Responda apenas com base no contexto fornecido. Mantenha um tom positivo e encorajador ao interagir com o usuário.\"\n",
        "\n",
        "url = \"https://i.postimg.cc/nz4ZskZn/Gemini-Generated-Image-ddohr6ddohr6ddoh-Edited-1.jpg\"    # URL da imagem do Zig\n"
      ],
      "metadata": {
        "id": "ma1tWP_97xFP"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializando o Modelo (2)\n",
        "\n",
        "# Verificação inicial das disponibilidades\n",
        "#for modelo in genai.list_models():\n",
        "#  if 'generateContent' in modelo.supported_generation_methods:\n",
        "#    print(modelo.name)\n",
        "\n",
        "# Definição do Modelo a ser usado\n",
        "\n",
        "# Opção 1\n",
        "#model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "#                              generation_config=generation_config,\n",
        "#                              system_instruction=system_instruction, #Instruções de personalidade\n",
        "#                              safety_settings=safety_settings)\n",
        "\n",
        "# Opção 2\n",
        "#model = genai.GenerativeModel(model_name=\"1.0-pro-latest\",\n",
        "#                              generation_config=generation_config,\n",
        "#                              system_instruction=system_instruction, #Instruções de personalidade\n",
        "#                              safety_settings=safety_settings)\n",
        "\n",
        "# Opção 3 - É a única que aceita as instruções iniciais personalizadas.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\",\n",
        "                              generation_config=generation_config,\n",
        "                              system_instruction=system_instruction, #Instruções de personalidade\n",
        "                              safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "posaUF4iq8Xo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preparando a Base de Conhecimento"
      ],
      "metadata": {
        "id": "TlzIZLkOROSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alimentando a base de conhecimento com PDFs\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print('Image(url=url)')\n",
        "\n",
        "Mensagem_carrega_PDF = 'Faça o **carregamento** (*upload*) de um ou mais arquivos em **PDF** (SELECIONE TODOS de uma só vez) que farão parte da Base de Conhecimento do Chatbot:'\n",
        "\n",
        "# Verifica se já existem arquivos PDF no diretório de destino\n",
        "arquivos_pdf_existentes = [arq for arq in os.listdir(diretorio_destino) if arq.endswith('.pdf')]\n",
        "\n",
        "if arquivos_pdf_existentes:\n",
        "  display(Markdown(\"Os seguintes arquivos PDF já estão no diretório:\"))\n",
        "  for arquivo in arquivos_pdf_existentes:\n",
        "    print(f\"- {arquivo}\")\n",
        "\n",
        "while True:\n",
        "  display(Markdown(Mensagem_carrega_PDF))\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    print(f'Arquivo \"{filename}\" carregado com sucesso.')\n",
        "  arquivos_pdf_existentes = [arq for arq in os.listdir(diretorio_destino) if arq.endswith('.pdf')]\n",
        "  if arquivos_pdf_existentes:\n",
        "    display(Markdown(\"Base de Conhecimento preparada.\"))\n",
        "    display(Markdown(\"Os seguintes arquivos PDF já estão no diretório:\"))\n",
        "    for arquivo in arquivos_pdf_existentes:\n",
        "      print(f\"- {arquivo}\")\n",
        "    break\n",
        "  else:\n",
        "    display(Markdown(\"**ALERTA:** Nenhum arquivo foi carregado ainda. Isso impede que eu funcione adequadamente.\"))\n",
        "    continue\n",
        "\n",
        "# Versão futura\n",
        "# Alimentando a base de conhecimentos com links externos\n",
        "#\n",
        "# Alimentando a base de conhecimento com outros tipos de arquivo...\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "SbDYqlTVGhdU",
        "outputId": "6953f8ef-be0b-407d-ec24-7e4c02c447d5"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image(url=url)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Faça o **carregamento** (*upload*) de um ou mais arquivos em **PDF** (SELECIONE TODOS de uma só vez) que farão parte da Base de Conhecimento do Chatbot:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f1e468fc-241d-4a54-a8f6-a8c8c1fda443\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f1e468fc-241d-4a54-a8f6-a8c8c1fda443\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ALERTA:** Nenhum arquivo foi carregado ainda. Isso impede que eu funcione adequadamente."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Faça o **carregamento** (*upload*) de um ou mais arquivos em **PDF** (SELECIONE TODOS de uma só vez) que farão parte da Base de Conhecimento do Chatbot:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b27e00b2-73dc-4741-ac6f-5088b723f6dd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b27e00b2-73dc-4741-ac6f-5088b723f6dd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving FAQ de Energia.pdf to FAQ de Energia.pdf\n",
            "Arquivo \"FAQ de Energia.pdf\" carregado com sucesso.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Base de Conhecimento preparada."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Os seguintes arquivos PDF já estão no diretório:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- FAQ de Energia.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Executando o Trabalho"
      ],
      "metadata": {
        "id": "iDkuUqPPSmDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(url=url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "6s3Z0fXp49Si",
        "outputId": "cbd82db1-c612-4014-f704-69e22b5df76c"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://i.postimg.cc/nz4ZskZn/Gemini-Generated-Image-ddohr6ddohr6ddoh-Edited-1.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import hashlib\n",
        "import PyPDF2\n",
        "import glob # Importe o módulo glob\n",
        "\n",
        "Image(url=url)\n",
        "\n",
        "def extract_pdf_pages(directory: str) -> list[str]:\n",
        "    parts = []\n",
        "    for filename in glob.glob(f\"{directory}/*.pdf\"):  # Encontre todos os PDFs no diretório\n",
        "        parts.append(f\"--- START OF PDF {filename} ---\")\n",
        "\n",
        "        # Lógica para ler o PDF e retornar uma lista de páginas:\n",
        "        with open(filename, 'rb') as pdf_file:\n",
        "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "            pages = []\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num].extract_text()\n",
        "                pages.append(page)\n",
        "\n",
        "        for index, page in enumerate(pages):\n",
        "            parts.append(f\"--- PAGE {index} ---\")\n",
        "            parts.append(page)\n",
        "    return parts\n",
        "\n",
        "convo = model.start_chat(history=[\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"parts\": extract_pdf_pages(\"/content/\") # Passa o diretório\n",
        "    }\n",
        "])\n",
        "\n",
        "# Início da interação\n",
        "\n",
        "display(Markdown('Olá, sou o Zig. Estou aqui pra responder suas perguntas sobre a base de conhecimento carregada e sobre mim. 😊'))\n",
        "display(Markdown('Se quiser interromper o chat, **tecle ENTER duas vezes seguidas** com o campo de escrita vazio. Como posso te ajudar?'))\n",
        "\n",
        "entradas_vazias_consecutivas = 0    # Contador de tecla ENTER vazia\n",
        "\n",
        "# Mantendo o diálogo\n",
        "\n",
        "while entradas_vazias_consecutivas < 2:\n",
        "  prompt = input('Escreva aqui: ')\n",
        "  if prompt.strip() == \"\":\n",
        "    entradas_vazias_consecutivas += 1\n",
        "  else:\n",
        "    entradas_vazias_consecutivas = 0\n",
        "    convo.send_message(prompt)\n",
        "    display(Markdown(convo.last.text))\n",
        "\n",
        "# Encerramento\n",
        "\n",
        "display(Markdown('Obrigado por ter interagido comigo. Volte sempre.'))\n",
        "\n",
        "# Fim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "gSx-V_JsdtOo",
        "outputId": "499f61da-0d75-4bc0-a863-f4931a0302b2"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Olá, sou o Zig. Estou aqui pra responder suas perguntas sobre a base de conhecimento carregada e sobre mim. 😊"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Se quiser interromper o chat, **tecle ENTER duas vezes seguidas** com o campo de escrita vazio. Como posso te ajudar?"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Escreva aqui: Qual o seu nome\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Olá! Meu nome é ZIG, e estou aqui para te ajudar 😊. Como posso ser útil hoje? 😄 \n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Escreva aqui: Tchau\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Tchau! Foi um prazer conversar com você. 😊  Espero que tenha um ótimo dia! 😄  Se precisar de algo mais, é só chamar! 😉 \n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Escreva aqui: \n",
            "Escreva aqui: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Obrigado por ter interagido comigo. Volte sempre."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Auxiliares e uso futuro"
      ],
      "metadata": {
        "id": "QdRnnIbc8PQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rotinas auxiliares para atividades de manutenção e fora do processo normal. Futuramente poderão ser incorporadas."
      ],
      "metadata": {
        "id": "f5LQOHV_9tdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apagar os arquivos carregados anteriormente #####################################################\n",
        "\n",
        "import os\n",
        "\n",
        "# Lista os arquivos no diretório atual\n",
        "arquivos_no_diretorio = os.listdir()\n",
        "\n",
        "# Itera sobre os arquivos e apaga os arquivos PDF\n",
        "for arquivo in arquivos_no_diretorio:\n",
        "  if arquivo.endswith(\".pdf\"):  # Verifica se o arquivo é um PDF\n",
        "    os.remove(arquivo)\n",
        "    print(f'Arquivo \"{arquivo}\" apagado com sucesso.')\n",
        "\n",
        "print(\"Não há ou todos os arquivos PDF foram apagados.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvU-km-nD7mC",
        "outputId": "b9f7ebc3-99f2-4362-dc63-b6e048d60a77"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo \"FAQ de Energia.pdf\" apagado com sucesso.\n",
            "Arquivo \"Orientações Gerais Grupo BNI BH Premium.pdf\" apagado com sucesso.\n",
            "Não há ou todos os arquivos PDF foram apagados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostra os arquivos na área de trabalho #######################################\n",
        "\n",
        "import os\n",
        "\n",
        "# Diretório de destino dos arquivos PDF\n",
        "#diretorio_destino = '/content/'\n",
        "\n",
        "# Lista os arquivos no diretório atual\n",
        "arquivos_no_diretorio = os.listdir()\n",
        "\n",
        "# Itera sobre os arquivos e exibe o caminho completo\n",
        "for arquivo in arquivos_no_diretorio:\n",
        "  caminho_completo = os.path.abspath(arquivo)  # Obtém o caminho completo do arquivo\n",
        "  print(f'Arquivo: {arquivo}, Caminho: {caminho_completo}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1ta-MbKEoac",
        "outputId": "1cde3d4b-386e-4cf2-ca76-0bd38aaf491f"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo: .config, Caminho: /content/.config\n",
            "Arquivo: sample_data, Caminho: /content/sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica se algum arquivo foi carregado ################################################ COM FALHA\n",
        "if uploaded:\n",
        "  display(Markdown(\"Os seguintes arquivos foram carregados:\"))   #print(\"Os seguintes arquivos foram carregados:\")\n",
        "  for filename in uploaded.keys():\n",
        "    print(f\"- {filename}\")\n",
        "else:\n",
        "  display(Markdown(\"**ALERTA:** Nenhum arquivo foi carregado ainda. Isso impede que eu funcione adequadamente.\"))   #print(\"Nenhum arquivo foi carregado ainda.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "NkC5zGNd9_-0",
        "outputId": "bab2d6ae-2f8e-451a-e5da-d8110de3583c"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Os seguintes arquivos foram carregados:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Orientações Gerais Grupo BNI BH Premium.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resposta mais descontraída. Uso futuro.\n",
        "prompt = f\"Reescreva esse texto de uma forma mais descontraída, sem adicionar informações que não façam parte do texto: {convo.last.text}\"\n",
        "\n",
        "model_2 = genai.GenerativeModel(\"gemini-1.0-pro\",\n",
        "                                generation_config=generation_config)\n",
        "response = model_2.generate_content(prompt)\n",
        "\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "KdThXU-rAF5F",
        "outputId": "34859872-b629-41d4-b475-35a17694482d"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'text'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-222-d4a23e7c56fb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Resposta mais descontraída. Uso futuro.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Reescreva esse texto de uma forma mais descontraída, sem adicionar informações que não façam parte do texto: {convo.last.text}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model_2 = genai.GenerativeModel(\"gemini-1.0-pro\",\n\u001b[1;32m      5\u001b[0m                                 generation_config=generation_config)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
          ]
        }
      ]
    }
  ]
}